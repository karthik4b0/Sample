bulkUpload:
  maxDocumentSize: 5 # Max documents per request
  simultaneousRequests: 8 # Number of simultaneous requests
  timeout: 10 # Timeout in minutes for processing

import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Service;
import java.util.concurrent.*;
import java.util.List;
import java.util.ArrayList;
import java.util.Date;
import java.util.concurrent.atomic.AtomicInteger;
import java.util.stream.Collectors;

@Service
public class BulkUploadPublishService {

    // Injecting values from application.yml
    @Value("${bulkUpload.maxDocumentSize}")
    private int maxDocumentSize; // 5 documents per request

    @Value("${bulkUpload.simultaneousRequests}")
    private int simultaneousRequests; // 8 simultaneous requests

    @Value("${bulkUpload.timeout}")
    private int timeout; // Timeout in minutes

    @Autowired
    private UtilsService utilsService;

    @Autowired
    private DocumentService documentService;

    @Autowired
    private BulkUploadDocumentsRepository bulkUploadDocumentsRepository;

    @Autowired
    private BulkUploadRepository bulkUploadRepository;

    public BulkUploadPublishResponseData publishBulkUpload(String bulkUploadGuid, String authUserId, String requestTrackingId) {
        UserEntitlements userEntitlements = getUserEntitlements();

        BulkUploadPublishResponseData bulkUploadPublishResponseData = new BulkUploadPublishResponseData();

        BulkUpload aBulkUpload = validateParamsAndGetBulkUpload(bulkUploadGuid, authUserId, requestTrackingId);

        List<BulkUploadDocuments> allByBulkUploadId = bulkUploadDocumentsRepository.findAllByBulkUploadId(aBulkUpload.getBulkUploadId());
        List<BulkUploadDocuments> metaDataValidatedList = allByBulkUploadId.stream()
                .filter(p -> p.isMetadataValidatedF1() && !p.isErrorF1())
                .collect(Collectors.toList());

        List<Document> docList = new ArrayList<>();

        if (!CollectionUtils.isNullOrEmpty(metaDataValidatedList)) {
            metaDataValidatedList.forEach(uploadDocuments -> {
                Document document = uploadDocuments.getDocument();
                document.setVisibleFl(true);
                document.setStagedF1(false);
                document.setDeletedFl(false);
                document.setLastChangedDate(new Date());
                uploadDocuments.setPublishFl(true);
                bulkUploadDocumentsRepository.save(uploadDocuments);
                uploadDocuments.setDocument(document);
                docList.add(document);
            });
            documentService.saveAll(docList);
            bulkUploadDocumentsRepository.saveAll(allByBulkUploadId);
            aBulkUpload.setPublishFl(true);
            aBulkUpload.setUpdateDate(new Date());
            bulkUploadRepository.save(aBulkUpload);

            // Ensure the values from application.yml are used
            final int MAX_DOCUMENTS_PER_REQUEST = maxDocumentSize; // 5 documents per request
            final int SIMULTANEOUS_REQUESTS = simultaneousRequests; // 8 simultaneous requests
            final int TOTAL_DOCUMENTS_IN_BATCH = MAX_DOCUMENTS_PER_REQUEST * SIMULTANEOUS_REQUESTS; // 40 documents in total

            // Use a fixed thread pool to limit the number of parallel requests
            ExecutorService executorService = Executors.newFixedThreadPool(SIMULTANEOUS_REQUESTS);

            // Partition the documents into chunks of 40 (total batch size)
            List<List<Document>> documentBatches = ListUtils.partition(docList, TOTAL_DOCUMENTS_IN_BATCH);

            // Submit tasks for processing each batch of 40 documents
            List<Future<?>> futures = new ArrayList<>();
            for (List<Document> batch : documentBatches) {
                Future<?> future = executorService.submit(() -> {
                    try {
                        // Split each batch into smaller chunks of 5 documents (per request)
                        List<List<Document>> smallBatches = ListUtils.partition(batch, MAX_DOCUMENTS_PER_REQUEST);

                        // Process each small batch (of 5 documents) in parallel
                        List<Future<?>> batchFutures = new ArrayList<>();
                        for (List<Document> smallBatch : smallBatches) {
                            batchFutures.add(executorService.submit(() -> {
                                try {
                                    // Push the batch to UE and update
                                    utilsService.pushTOUEAndUpdate(requestTrackingId, userEntitlements, smallBatch, new ConcurrentHashMap<>(), new ConcurrentHashMap<>());
                                    logger.info("Completed pushTOUEAndUpdate processing for small batch of size: " + smallBatch.size());
                                } catch (Exception e) {
                                    logger.error("Error occurred while processing small batch.", e);
                                }
                            }));
                        }

                        // Wait for all small batches to complete
                        for (Future<?> smallBatchFuture : batchFutures) {
                            smallBatchFuture.get();
                        }

                    } catch (Exception e) {
                        logger.error("Error occurred while processing large batch.", e);
                    }
                });
                futures.add(future);
            }

            // Wait for all batch tasks to complete
            for (Future<?> future : futures) {
                try {
                    future.get(); // block until the task completes
                } catch (InterruptedException | ExecutionException e) {
                    logger.error("Error while waiting for batch processing to complete.", e);
                }
            }

            // Shutdown executor after use
            executorService.shutdown();
        }

        BulkUploadPublishResponse bulkUploadPublishResponse = new BulkUploadPublishResponse();
        bulkUploadPublishResponse.setBulkUploadGuid(aBulkUpload.getBulkUploadGUID());
        bulkUploadPublishResponse.setBulkUploadDocuments(new ArrayList<>());
        for (BulkUploadDocuments bulkUploadDocument : allByBulkUploadId) {
            buildBulkUploadPublishResponse(bulkUploadPublishResponse, bulkUploadDocument);
        }
        bulkUploadPublishResponseData.setData(bulkUploadPublishResponse);
        return bulkUploadPublishResponseData;
    }
}

